# ğŸš€ End-to-End Data Engineering Project on Snowflake

## ğŸ“˜ Project Overview
This project demonstrates a **real-world end-to-end data engineering pipeline** using the **Snowflake Data Platform**.  
It involves **extracting JSON data from an API**, ingesting it into **Snowflake (Raw Layer)**, performing **data transformation and cleansing**, modeling the data into a **Star Schema**, and finally **visualizing insights using Streamlit dashboards**.

---

## ğŸ§± Architecture Overview

**Pipeline Flow:**
1. **Extract** JSON data from a REST API.  
2. **Load** data directly into Snowflake Raw Layer _or_ upload to **AWS S3** for auto-ingestion using Snowpipe.  
3. **Transform & Cleanse** data into curated tables (Star Schema).  
4. **Visualize** insights with **Streamlit dashboards**.

> The architecture diagram (Project Architecture.png) shows how data flows from the API source â†’ S3/Snowflake â†’ Transformation Layer â†’ Visualization.

---

## ğŸ§© Project Structure

```
snowflake_e2e_project/
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ extract_and_upload_to_s3.py        # Extracts API data and uploads JSON files to S3
â”‚   â””â”€â”€ extract_and_load_direct.py         # Directly loads API JSON data into Snowflake RAW layer
â”‚
â”œâ”€â”€ snowflake/
â”‚   â””â”€â”€ pipeline_setup.sql                 # SQL script for database, schema, stage, and task setup
â”‚
â”œâ”€â”€ requirements.txt                       # All Python dependencies
â””â”€â”€ README.md                              # Project documentation
```

---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Clone Repository

```bash
git clone https://github.com/<your-username>/snowflake_e2e_project.git
cd snowflake_e2e_project
```

### 2ï¸âƒ£ Create & Activate Virtual Environment

```bash
python -m venv venv
source venv/bin/activate  # For macOS/Linux
venv\Scripts\activate   # For Windows
```

### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Configure Environment Variables

Create a `.env` file in the project root with the following variables:

```
# API
API_ENDPOINT=https://api.example.com/data

# AWS
AWS_ACCESS_KEY_ID=your_aws_key
AWS_SECRET_ACCESS_KEY=your_aws_secret
AWS_S3_BUCKET=your_bucket_name

# Snowflake
SNOWFLAKE_USER=your_user
SNOWFLAKE_PASSWORD=your_password
SNOWFLAKE_ACCOUNT=your_account
SNOWFLAKE_WAREHOUSE=COMPUTE_WH
SNOWFLAKE_DATABASE=PROJ_E2E_DB
SNOWFLAKE_SCHEMA=RAW
```

---

## ğŸ§  Scripts Description

### ğŸ”¹ `extract_and_upload_to_s3.py`
- Extracts JSON data from the API.
- Saves it locally and uploads it to an **S3 bucket**.
- Snowpipe automatically ingests this data into Snowflakeâ€™s RAW layer.

### ğŸ”¹ `extract_and_load_direct.py`
- Connects directly to Snowflake.
- Inserts JSON data straight into the RAW table for immediate analysis.

---

## ğŸ§¾ Snowflake SQL Setup (`pipeline_setup.sql`)

The SQL script performs the following:
- Creates **RAW** and **CLEAN** schemas.  
- Defines **stages**, **tables**, **streams**, and **tasks**.  
- Automates ingestion and transformation using **Snowpipe + Streams + Tasks**.  

Example command to run the setup:
```sql
!snowsql -a <account> -u <user> -f snowflake/pipeline_setup.sql
```

---

## ğŸ“Š Streamlit Dashboard

Once data is cleaned and modeled, you can visualize it using **Streamlit**.

Example run command:
```bash
streamlit run app.py
```

Your dashboard will display **real-time insights** from Snowflakeâ€™s CLEAN layer.

---

## ğŸŒŸ Highlights

âœ… Automated ingestion via **Snowpipe**  
âœ… Data freshness maintained with **Streams & Tasks**  
âœ… Clear separation between **RAW** and **CLEAN** layers  
âœ… Interactive visualization using **Streamlit**  

---

## ğŸ§° Requirements

All dependencies are listed in `requirements.txt`:

```
boto3
requests
snowflake-connector-python
python-dotenv
pandas
streamlit
```

---

## ğŸ Next Steps

- Add unit tests for transformation logic  
- Deploy Streamlit app to **Streamlit Cloud or AWS EC2**  
- Integrate **dbt or Airflow** for pipeline orchestration

---

## ğŸ’¡ Author

**Nelson Ukaegbu**  
_Data Engineer | Cloud & Analytics Specialist_  

---

## ğŸ“œ License

MIT License Â© 2025 Nelson Ukaegbu
